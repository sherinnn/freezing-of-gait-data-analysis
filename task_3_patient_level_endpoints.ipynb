{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db1193ac",
   "metadata": {},
   "source": [
    "## Things achieved in this notebook:\n",
    "- ranked subjects from worst to best for FoG burden\n",
    "- Derive endpoints such as FoG burden (% of experiment time labeled/predicted as FoG)\n",
    "- episode rate (number of FoG episodes per minute), mean episode duration, longest episode duration, etc. \n",
    "- Defined a single composite severity score \n",
    "- final ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e1aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bda658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52faa936",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_STEP_SEC = 0.5\n",
    "WINDOW_LEN_SEC = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422ec43",
   "metadata": {},
   "source": [
    "### 1) Converting labels into episodes\n",
    "windows_to_episodes(binary_labels)\n",
    "\n",
    "Input: something like [0,0,1,1,1,0,0,1,0]\n",
    "Output: list of window-index ranges where label stayed 1, e.g. [(2,4), (7,7)]\n",
    "\n",
    "How it works:\n",
    "\n",
    "It scans through labels and detects transitions:\n",
    "\n",
    "0 → 1: starts an episode\n",
    "\n",
    "1 → 0: ends the episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2497a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows_to_episodes(binary_labels):\n",
    "    \"\"\"Return episodes as list of (start_idx, end_idx) indices in the window sequence.\"\"\"\n",
    "    eps = []\n",
    "    in_ep = False\n",
    "    s = None\n",
    "    for i, v in enumerate(binary_labels):\n",
    "        if v == 1 and not in_ep:\n",
    "            in_ep = True\n",
    "            s = i\n",
    "        elif v == 0 and in_ep:\n",
    "            eps.append((s, i - 1))\n",
    "            in_ep = False\n",
    "    if in_ep:\n",
    "        eps.append((s, len(binary_labels) - 1))\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c3654",
   "metadata": {},
   "source": [
    "### 2) Episode duration in seconds\n",
    "episode_durations_sec(episodes)\n",
    "\n",
    "Takes episode ranges like (start_idx, end_idx) and converts to time:\n",
    "\n",
    "duration = (end - start) * WINDOW_STEP_SEC + WINDOW_LEN_SEC\n",
    "\n",
    "\n",
    "Why this formula?\n",
    "\n",
    "If an episode spans multiple windows, each additional window adds one stride (0.5s) of extra time coverage.\n",
    "\n",
    "Even a single window episode (start=end) still covers WINDOW_LEN_SEC (4s).\n",
    "\n",
    "Example:\n",
    "\n",
    "Episode (2,4) spans 3 windows (2→4):\n",
    "\n",
    "(4-2)*0.5 + 4.0 = 1.0 + 4.0 = 5.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19029847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_durations_sec(episodes):\n",
    "    \"\"\"Convert episode window-index ranges into seconds.\"\"\"\n",
    "    if not episodes:\n",
    "        return np.array([], dtype=float)\n",
    "    # duration = (end-start)*step + window_len\n",
    "    return np.array([(e - s) * WINDOW_STEP_SEC + WINDOW_LEN_SEC for s, e in episodes], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83dc0a0",
   "metadata": {},
   "source": [
    "### 3) Compute subject-level endpoints\n",
    "compute_subject_endpoints(df, label_col)\n",
    "\n",
    "df must have at least:\n",
    "\n",
    "subject_id, run_id, window_id\n",
    "\n",
    "and the label column you name in label_col (e.g. \"label\" or \"y_pred\")\n",
    "\n",
    "It does two levels:\n",
    "\n",
    "A) Run-level (per subject_id + run_id)\n",
    "\n",
    "For each run, it computes:\n",
    "\n",
    "Ordering: sorts by subject_id, run_id, window_id to ensure correct episode parsing.\n",
    "\n",
    "Run duration (minutes):\n",
    "\n",
    "run_minutes = (len(y) * WINDOW_STEP_SEC) / 60\n",
    "\n",
    "\n",
    "This approximates run length based on stride timing.\n",
    "(Note: With sliding windows, “true” coverage might be slightly longer/shorter depending on how windows were created, but this is a consistent approximation.)\n",
    "\n",
    "FoG burden (fraction of windows labeled 1):\n",
    "\n",
    "fog_burden = mean(y == 1)\n",
    "\n",
    "\n",
    "This is window-level prevalence, not “percent time” exactly (but correlated).\n",
    "\n",
    "Episodes + durations: uses the earlier functions.\n",
    "\n",
    "Episode rate per minute:\n",
    "\n",
    "ep_rate = n_episodes / run_minutes\n",
    "\n",
    "\n",
    "Mean and max episode duration (seconds):\n",
    "\n",
    "If no episodes, both are set to 0.0\n",
    "\n",
    "It stores these in run_endpoints.\n",
    "\n",
    "B) Subject-level aggregation (across runs)\n",
    "\n",
    "It aggregates runs into one row per subject.\n",
    "\n",
    "Key detail: it uses weighted averages by run duration for most metrics:\n",
    "\n",
    "fog_burden_pct = 100 * wavg(fog_burden, run_minutes)\n",
    "episode_rate_per_min = wavg(ep_rate, run_minutes)\n",
    "mean_episode_dur_s = wavg(mean_dur, run_minutes)\n",
    "\n",
    "\n",
    "Why weight by run length? Longer runs should contribute more than short runs.\n",
    "\n",
    "max_episode_dur_s is taken as the maximum across runs (not weighted).\n",
    "\n",
    "n_episodes is summed across runs.\n",
    "\n",
    "total_minutes is total run time.\n",
    "\n",
    "It returns a per-subject dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bac1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subject_endpoints(df, label_col):\n",
    "    \"\"\"\n",
    "    df: window-level dataframe for ALL subjects\n",
    "    label_col: 'label' for ground truth OR 'y_pred' for predictions\n",
    "    returns: subject-level endpoints dataframe\n",
    "    \"\"\"\n",
    "    out_rows = []\n",
    "\n",
    "    # Ensure ordering\n",
    "    df2 = df.copy()\n",
    "    df2 = df2.sort_values([\"subject_id\", \"run_id\", \"window_id\"])\n",
    "\n",
    "    for (sid, rid), run_df in df2.groupby([\"subject_id\", \"run_id\"], sort=False):\n",
    "        y = run_df[label_col].to_numpy().astype(int)\n",
    "\n",
    "        # Run duration (minutes) approximated from step timing\n",
    "        run_minutes = (len(y) * WINDOW_STEP_SEC) / 60.0\n",
    "\n",
    "        # FoG burden for this run: % windows labeled FoG\n",
    "        fog_burden = float(np.mean(y == 1)) if len(y) else np.nan\n",
    "\n",
    "        # Episodes and durations\n",
    "        eps = windows_to_episodes(y)\n",
    "        durs = episode_durations_sec(eps)\n",
    "\n",
    "        ep_rate = (len(eps) / run_minutes) if run_minutes > 0 else np.nan\n",
    "        mean_dur = float(np.mean(durs)) if len(durs) else 0.0\n",
    "        max_dur = float(np.max(durs)) if len(durs) else 0.0\n",
    "\n",
    "        out_rows.append({\n",
    "            \"subject_id\": sid,\n",
    "            \"run_id\": rid,\n",
    "            \"run_minutes\": run_minutes,\n",
    "            \"fog_burden\": fog_burden,                 # fraction (0-1)\n",
    "            \"episode_rate_per_min\": ep_rate,\n",
    "            \"mean_episode_dur_s\": mean_dur,\n",
    "            \"max_episode_dur_s\": max_dur,\n",
    "            \"n_episodes\": len(eps),\n",
    "        })\n",
    "\n",
    "    run_endpoints = pd.DataFrame(out_rows)\n",
    "\n",
    "    # Aggregate runs -> subject level, weighted by run duration\n",
    "    def wavg(x, w):\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        w = np.asarray(w, dtype=float)\n",
    "        m = ~np.isnan(x) & ~np.isnan(w) & (w > 0)\n",
    "        if not np.any(m):\n",
    "            return np.nan\n",
    "        return float(np.sum(x[m] * w[m]) / np.sum(w[m]))\n",
    "\n",
    "    subject_rows = []\n",
    "    for sid, s_df in run_endpoints.groupby(\"subject_id\"):\n",
    "        w = s_df[\"run_minutes\"].to_numpy()\n",
    "\n",
    "        subject_rows.append({\n",
    "            \"subject_id\": sid,\n",
    "            \"total_minutes\": float(np.sum(w)),\n",
    "            \"fog_burden_pct\": 100.0 * wavg(s_df[\"fog_burden\"], w),\n",
    "            \"episode_rate_per_min\": wavg(s_df[\"episode_rate_per_min\"], w),\n",
    "            \"mean_episode_dur_s\": wavg(s_df[\"mean_episode_dur_s\"], w),\n",
    "            \"max_episode_dur_s\": float(np.max(s_df[\"max_episode_dur_s\"])) if len(s_df) else np.nan,\n",
    "            \"n_episodes\": int(np.sum(s_df[\"n_episodes\"])),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(subject_rows).sort_values(\"subject_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4a0e4",
   "metadata": {},
   "source": [
    "### 4) Robust z-score helper\n",
    "robust_z(x)\n",
    "\n",
    "Computes a z-score using median and MAD (median absolute deviation), which is more stable with outliers:\n",
    "\n",
    "z = (x - median) / (1.4826 * MAD)\n",
    "\n",
    "\n",
    "1.4826 makes MAD comparable to standard deviation for normal data.\n",
    "\n",
    "If MAD is 0 (all values identical), it falls back to just (x - median)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77f4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_z(x):\n",
    "    \"\"\"Robust z-score using median and MAD (less sensitive to outliers).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    med = np.nanmedian(x)\n",
    "    mad = np.nanmedian(np.abs(x - med))\n",
    "    if mad == 0 or np.isnan(mad):\n",
    "        return (x - med)  # fallback\n",
    "    return (x - med) / (1.4826 * mad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fdb6a",
   "metadata": {},
   "source": [
    "### 5) Composite severity score + ranking\n",
    "add_composite_and_rank(subject_df, weights=None)\n",
    "\n",
    "It builds a severity score by:\n",
    "\n",
    "Robust z-scoring each metric\n",
    "\n",
    "Weighted sum:\n",
    "\n",
    "Default weights:\n",
    "\n",
    "- 40% FoG burden percent\n",
    "- 30% episode rate per minute\n",
    "- 20% mean episode duration\n",
    "- 10% max episode duration\n",
    "\n",
    "Then it:\n",
    "\n",
    "sorts by severity_score descending\n",
    "\n",
    "adds rank_worst_to_best = 1,2,3,…\n",
    "\n",
    "So higher score = “worse” (more burden, more frequent episodes, longer episodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48507ba",
   "metadata": {},
   "source": [
    "**The goal of the composite severity score is to rank subjects by overall clinical impact of FoG, not by any single metric.**\n",
    "- 40% — FoG burden percent\n",
    "    - Primary indicator of overall impact\n",
    "    - Captures total time affected, integrating both frequency and duration implicitly\n",
    "    - Most closely aligned with day-to-day functional impairment\n",
    "    - This best reflects overall lived burden, so it dominates the score\n",
    "- 30% — Episode rate per minute\n",
    "    - How often FoG disrupts movement\n",
    "    - Frequency matters almost as much as total burden, but alone it can overemphasize brief episodes\n",
    "- 20% — Mean episode duration\n",
    "    - Reflects how difficult it is to recover once FoG begins\n",
    "- 10% — Max episode duration\n",
    "    - Worst-case severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b4b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_composite_and_rank(subject_df, weights=None):\n",
    "    \"\"\"\n",
    "    Build a composite severity score.\n",
    "    Default weights prioritize burden + episode rate, then duration.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            \"fog_burden_pct\": 0.40,\n",
    "            \"episode_rate_per_min\": 0.30,\n",
    "            \"mean_episode_dur_s\": 0.20,\n",
    "            \"max_episode_dur_s\": 0.10,\n",
    "        }\n",
    "\n",
    "    z_burden = robust_z(subject_df[\"fog_burden_pct\"])\n",
    "    z_rate   = robust_z(subject_df[\"episode_rate_per_min\"])\n",
    "    z_mean   = robust_z(subject_df[\"mean_episode_dur_s\"])\n",
    "    z_max    = robust_z(subject_df[\"max_episode_dur_s\"])\n",
    "\n",
    "    score = (\n",
    "        weights[\"fog_burden_pct\"]       * z_burden +\n",
    "        weights[\"episode_rate_per_min\"] * z_rate +\n",
    "        weights[\"mean_episode_dur_s\"]   * z_mean +\n",
    "        weights[\"max_episode_dur_s\"]    * z_max\n",
    "    )\n",
    "\n",
    "    out = subject_df.copy()\n",
    "    out[\"severity_score\"] = score\n",
    "    out = out.sort_values(\"severity_score\", ascending=False).reset_index(drop=True)\n",
    "    out[\"rank_worst_to_best\"] = np.arange(1, len(out) + 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb21c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subject = compute_subject_endpoints(df, label_col=\"label\")\n",
    "true_ranked  = add_composite_and_rank(true_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f24faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>total_minutes</th>\n",
       "      <th>fog_burden_pct</th>\n",
       "      <th>episode_rate_per_min</th>\n",
       "      <th>mean_episode_dur_s</th>\n",
       "      <th>max_episode_dur_s</th>\n",
       "      <th>n_episodes</th>\n",
       "      <th>severity_score</th>\n",
       "      <th>rank_worst_to_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>26.100629</td>\n",
       "      <td>1.056604</td>\n",
       "      <td>18.321429</td>\n",
       "      <td>25.5</td>\n",
       "      <td>14</td>\n",
       "      <td>1.306507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>35.966667</td>\n",
       "      <td>22.937905</td>\n",
       "      <td>1.556997</td>\n",
       "      <td>12.376822</td>\n",
       "      <td>33.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1.253844</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>29.941667</td>\n",
       "      <td>15.001392</td>\n",
       "      <td>0.701364</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.625601</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.591667</td>\n",
       "      <td>14.068899</td>\n",
       "      <td>1.011804</td>\n",
       "      <td>9.927001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.386367</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>12.628337</td>\n",
       "      <td>0.821355</td>\n",
       "      <td>12.734689</td>\n",
       "      <td>22.5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.293472</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>6.374696</td>\n",
       "      <td>0.204380</td>\n",
       "      <td>18.749722</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.043820</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>4.918451</td>\n",
       "      <td>0.428135</td>\n",
       "      <td>10.470795</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.398082</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>27.708333</td>\n",
       "      <td>4.360902</td>\n",
       "      <td>0.541353</td>\n",
       "      <td>8.349937</td>\n",
       "      <td>15.5</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.468262</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>35.616667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.362409</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>38.366667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.362409</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  total_minutes  fog_burden_pct  episode_rate_per_min  \\\n",
       "0           8      13.250000       26.100629              1.056604   \n",
       "1           5      35.966667       22.937905              1.556997   \n",
       "2           9      29.941667       15.001392              0.701364   \n",
       "3           3      34.591667       14.068899              1.011804   \n",
       "4           2      24.350000       12.628337              0.821355   \n",
       "5           6      34.250000        6.374696              0.204380   \n",
       "6           1      32.700000        4.918451              0.428135   \n",
       "7           7      27.708333        4.360902              0.541353   \n",
       "8           4      35.616667        0.000000              0.000000   \n",
       "9          10      38.366667        0.000000              0.000000   \n",
       "\n",
       "   mean_episode_dur_s  max_episode_dur_s  n_episodes  severity_score  \\\n",
       "0           18.321429               25.5          14        1.306507   \n",
       "1           12.376822               33.0          56        1.253844   \n",
       "2           16.333333               42.0          21        0.625601   \n",
       "3            9.927001               25.0          35        0.386367   \n",
       "4           12.734689               22.5          20        0.293472   \n",
       "5           18.749722               45.0           7        0.043820   \n",
       "6           10.470795               19.0          14       -0.398082   \n",
       "7            8.349937               15.5          15       -0.468262   \n",
       "8            0.000000                0.0           0       -1.362409   \n",
       "9            0.000000                0.0           0       -1.362409   \n",
       "\n",
       "   rank_worst_to_best  \n",
       "0                   1  \n",
       "1                   2  \n",
       "2                   3  \n",
       "3                   4  \n",
       "4                   5  \n",
       "5                   6  \n",
       "6                   7  \n",
       "7                   8  \n",
       "8                   9  \n",
       "9                  10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bfc27",
   "metadata": {},
   "source": [
    "- Subject 8 (rank 1) Highest FoG burden\n",
    "- Subject 5 (rank 2) Very high episode rate and number of episodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
